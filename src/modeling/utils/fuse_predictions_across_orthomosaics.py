import argparse
import os
import json

from collections import defaultdict
from shapely import Polygon

from dataset.constants import UNCLASSIFIED

def make_prediction_dict(label, confidence, polygon_id, label_source, geometry_source, views_considered, view_strategy):
    return {"Confidence": confidence,
            "Label": label,
            "Label Source": label_source,
            "Geometry Source": geometry_source,
            "ID":polygon_id,
            "Views Considered":views_considered,
            "Multi-View Fusion Strategy": view_strategy,
            "Multi-View Fusion Occured": views_considered > 1}

def get_predictions_by_file(polygon_data, predictions, id_2_model):
    resulting_predictions_by_file = defaultdict(lambda:{})
    for predictions_file in polygon_data.keys():
        for entry_data in polygon_data[predictions_file]:
            geometry_source = entry_data["geometry_source"] if "geometry_source" in entry_data.keys() else entry_data["source"]
            try:
                pred = predictions[entry_data["id"]]
                d = make_prediction_dict(label=pred["label"],
                                         confidence=pred["confidence"],
                                         polygon_id=entry_data["id"],
                                         label_source=id_2_model[entry_data["id"]],
                                         geometry_source=geometry_source,
                                         views_considered=1,
                                         view_strategy="N/A")
                resulting_predictions_by_file[predictions_file][entry_data["id"]] = d
            except KeyError:
                pass
    return resulting_predictions_by_file

def get_predictions_and_metadata_grouped_by_polygon(polygon_data_by_file, predictions, id_2_model):
    centroids = defaultdict(lambda:[])
    for filename in polygon_data_by_file.keys():
        for polygon_data in polygon_data_by_file[filename]:
            label = None
            geometry_source = None
            label_source = None
            try:
                label = predictions[polygon_data["id"]]
                geometry_source = polygon_data["source"]
                label_source = id_2_model[polygon_data["id"]]
            except KeyError:
                pass
            if label:
                centroid = Polygon([(x["lon"], x["lat"]) for x in polygon_data['EPSG:4326']]).centroid.coords[0]
                centroids[centroid].append([polygon_data["id"], geometry_source, label_source, label])

    return list(centroids.values())

def pick_max_confidence(predictions_grouped_by_polygon):
    fused_predictions = {}
    for labels in predictions_grouped_by_polygon:
        polygon_id, geometry_source, label_source, label = max(labels, key=lambda x:x[3]["confidence"]-(1 if x[3]["label"] == UNCLASSIFIED else 0))
        fused_predictions[polygon_id] = make_prediction_dict(label=label["label"],
                                                             confidence=label["confidence"],
                                                             polygon_id=polygon_id,
                                                             label_source=label_source,
                                                             geometry_source=geometry_source,
                                                             views_considered= len(labels),
                                                             view_strategy="Max Confidence" if len(labels) > 1 else "N/A")
    return fused_predictions

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Fused the predictions made across the different orthomosaics being considered')
    parser.add_argument('--save_path', type=str, help='The path to where the plots should be saved.')
    parser.add_argument('--building_polygons_folder', type=str, help='The folder where the initial building polygons are saved.')
    parser.add_argument('--predictions_folder', type=str, help='The folder where the predictions are saved.')
    args = parser.parse_args()

    print("Loading the predictions from :", args.predictions_folder)
    predictions_data = {}
    id_2_model_map = {}
    for file in os.listdir(args.predictions_folder):
        file_path = os.path.join(args.predictions_folder, file)
        if file_path.endswith(".json"):
            with open(file_path, "r") as f:
                data = json.loads(f.read())
                for predicted_polygon_id in data["preds"].keys():
                    id_2_model_map[predicted_polygon_id] = data["model_name"]
                predictions_data.update(data["preds"])

    print("Reading annotations from: ", args.building_polygons_folder)
    all_data = {}
    for file in os.listdir(args.building_polygons_folder):
        file_path = os.path.join(args.building_polygons_folder, file)
        with open(file_path, "r") as f:
            data = json.load(f)
            all_data[file] = data

    predictions_by_file = get_predictions_by_file(all_data, predictions_data, id_2_model_map)

    predictions_by_polygon = get_predictions_and_metadata_grouped_by_polygon(all_data, predictions_data, id_2_model_map)

    predictions_fused_by_confidence = pick_max_confidence(predictions_by_polygon)

    for file in predictions_by_file:
        with open(os.path.join(args.save_path, file), 'w') as f:
            json.dump(predictions_by_file[file], f)

    with open(os.path.join(args.save_path, "fused_predictions.json"), 'w') as f:
        json.dump(predictions_fused_by_confidence, f)
